---
title: Business Analytics | Modelo de classificação em um caso de Retorno do Investimento
author: Giuliano Sposito
date: '2022-01-18'
slug: 'classifier-model-and-return-of-investment'
categories:
  - data science
  - advanced business analytics
tags:
  - evaluation
  - machine learning
  - model
  - data science
  - classifier
  - random forest
  - metrics
subtitle: ''
lastmod: '2022-01-18T16:17:51-03:00'
authorLink: ''
description: ''
hiddenFromHomePage: no
hiddenFromSearch: no
featuredImage: 'images/post_cover.png'
featuredImagePreview: 'images/post_cover.png'
toc:
  enable: yes
math:
  enable: no
lightgallery: no
license: ''
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
# put rnotebook in the same workdir
# knitr::opts_knit$set(root.dir = normalizePath(rprojroot::find_rstudio_root_file())) 
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Você pode imaginar um caso de negócios real onde você aplica aprendizado de máquina para construir um classificador (Random Forest) e a precisão do acurácia não é a (única) métrica a ser observada e levanda em conta? Em cenários reais os custos e benefícios podem afetar um modelo em diferentes aspectos, muitas vezes retorno de um investimento é dependente do comportamento da métrica precisão (_precision_).

<!--more-->

### Introdução

Consultas médicas perdidas custam ao sistema de saúde dos EUA mais de US$ 150 bilhões por ano. Elas causam diretamente a perda de receita e a subutilização dos escaços e preciosos recursos médicos, além disso, também leva a longos tempos de espera de pacientes e a longo prazo eleva os custos médicos como um todo.

Nesse contexto, vamos construir um modelo preditivo para estimar se um paciente perderá uma consulta e usar a previsão para como base para tomada de ação a fim de tentar evitar o cancelamento.

### Dados

Obtivemos um [conjunto de dados](./assets/data.xlsx) com 7.463 consultas médicas em um período de três anos em uma clínica especializada. Nesse conjunto de dados cada linha corresponde a um compromisso e indica se foi cancelado ou não.

```{r loadData, cache=TRUE}
library(xlsx)
library(tidyverse)

# the life, the universe an everything else...
set.seed(42)

# data set
rawdata <- xlsx::read.xlsx("./assets/data.xlsx", sheetIndex = 1)

# basic clean_up
appdata <- rawdata %>% 
  as_tibble() %>% 
  janitor::clean_names() %>% 
  mutate_if(is.character, as.factor)

dim(appdata)
```

#### Visão geral dos dados

Vamos ver o aspecto geral do conjunto de dados

```{r eda}
skimr::skim(appdata)
```

No total, 1.662 dos 7.463 agendamentos foram cancelados, podemos ver na coluna **status** (nossa variável _target_).

### Modelo

Como estamos interessados em cancelamentos de compromissos, a variável alvo é descobrir se um agendamento foi cancelado ou não e o sucesso nesse contexto específico significa prever corretamente que um agendamento foi cancelado.

```{r model}
library(tidymodels)

# training & test data partition
appsplit <- initial_split(appdata)

# basic transformation
apprecp <- appsplit %>% 
  training() %>% 
  recipe(status ~ ., data=.) %>% 
  update_role(date_id, new_role = "id variable") %>% 
  update_role(status, new_role = "outcome") %>% 
  step_log(lag) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  prep() 

# training & test set
app_tr <- juice(apprecp)
app_ts <- bake(apprecp, testing(appsplit))

# fit a model
app_model <- rand_forest(trees = 100, mode="classification") %>% 
  set_engine("ranger") %>% 
  fit(status ~ . - date_id, data=app_tr)
```

We build a simple and direct [random forest](https://en.wikipedia.org/wiki/Random_forest) model using [Ranger](https://www.rdocumentation.org/packages/ranger/versions/0.13.1/topics/ranger) implementation through [Tidymodels](https://www.tidymodels.org/) package. 

```{r seeTheModel}
app_model
```

#### Avaliação

Quão bom é o nosso modelo?

```{r modelEval}
# eval it
app_pred <- predict(app_model, app_ts) %>%  # class outcome
  bind_cols(predict(app_model, app_ts, type = "prob")) %>% # class prob
  bind_cols(select(app_ts,status)) %>%  # true value
  relocate(status, everything())

# performance
cm <- app_pred %>% 
  conf_mat(status, .pred_class)

cm %>% 
  summary() %>% 
  select(-.estimator) %>% 
  knitr::kable()

# AUC
app_pred %T>% 
  roc_auc(.pred_Arrived, truth=status) %>% 
  roc_curve(.pred_Arrived, truth=status) %>% 
  autoplot()
```

### Desião de Negócio para Tomada de Ação

Com a previsão em mãos, podemos fazer uma ação de negócio para tentar reverter os cancelamentos de agendamentos. Vamos supor que podemos fazer uma ligação telefônica para qualquer pessoa prevista como "Cancelada" com um ou dois dias de antecedência e isso poderá reverter em torno de 30% dos agendamentos que seriam cancelados. Será que essa ação uma abordagem viável? É economicamente viável? Ou, pelo menos, mais em conta do que deixar o paciente cancelar sua consulta?

Para decidir isso precisamos estabelecer o valor de algumas variáveis para um modelo econômico de retorno, para este exercício podemos assumir:

* Custo de um telefonema: $5.00
* Taxa de reversão do cancelamento de agendamento: 30%
* Benefício de uma consulta não perdida: $60.00

Assim, podemos calcular um *Retorno do Investimento* (_RoI_) desta ação neste cenário:

```{r calcRoI}

# business variable
phone_cost   <- 5
reverse_rate <- .3
benefit      <- 60

# business case

# cost: phone to all patient predicted as "canceled"
total_cost  <- sum(cm$table["Cancelled",]) * phone_cost

# benefit: the reverse of 30% of patient that (in fact) would cancel the appointment
total_benefit <- cm$table["Cancelled","Cancelled"] * reverse_rate * benefit

# return of the investment
RoI <- total_benefit - total_cost

```

Então obtemos este resultado:

* Custo Total: `r sum(cm$table["Cancelled",]) ` * $`r phone_cost ` = $`r total_cost`
* Benefício Total: `r cm$table["Cancelled","Cancelled"]` * `r reverse_rate` * $`r benefit` = $`r total_benefit`
* Retorno: $`r total_benefit` - $`r total_cost` = $`r RoI`

Como vimos, com um _RoI_ de $`r RoI` vale a pena tomar esta ação.

Um aspecto essencial para prestarmos atenção, fazemos uma ligação a todos os pacientes que estão previstos como "cancelamento", mas só obtemos retorno em 30% (taxa de reversão) daqueles verdadeiramente identificados como "cancelamento", a.k.a, **Positivos Verdadeiros** (TP). Em outras palavras, o custo da ação é função de **Verdadeiros Positivos** (TP) mais **Falsos Positivos** (FP) mas o benefício da ação é função apenas de **Verdadeiros Positivos** (TP). Isso porque um **Falso Positivo** (FP) é um paciente previsto como "cancelamento" mas ele irá à consulta, então o telefonema não tráz nenhum benefício, apenas custo nesses casos.

#### Melhorando a Performance da Ação

Podemos melhorar o retorno da ação sem (necessariamente) melhorar o modelo? Como o _RoI_ é função da taxa entre **Verdadeiros Positivos** (TP) e **Verdadeiros Positivos** (TP) + **Falsos Positivos** (FP) (também conhecido como _Métrica de Precisão_) na proporção dos benefícios e custos, podemos _ajustar_ nosso classificador alterando o [_logístic threshold_](https://deepchecks.com/glossary/classification-threshold/) para alterar a _metrica de precisão_ do modelo a fim de maximizar o _RoI_.

Para ver isso na prática, vamos calcular o que acontece com nosso _RoI_ alterando o _threshold_ do classificador de 0 para 1 em incrementos de 0,01:

```{r thresholdRange}

# generate the confusion metrics in function of an threshold
genConfMatrix <- function(.threshold, .evalData){
  # reply as a tibble row
  # new truth vs prediction table
  tibble(
      truth=.evalData$status, 
      # the prediction as function of the customized threshold
      estimate=unique(.evalData$status)[as.integer(.evalData$.pred_Cancelled>=.threshold)+1]
    ) %>%
    # gen the confusion matrix
    conf_mat(truth, estimate) %>% 
    return()
}

# calculates the RoI based in the result of a confusion matrix
calcRoi <- function(.cm, .benefit=60, .cost=5, .rev_rate=.3){
  tibble(
    TP = .cm$table["Cancelled","Cancelled"],
    FP = .cm$table["Cancelled","Arrived"] ) %>% 
    mutate(
      # cost: phone to all patient predicted as "canceled"
      cost    = (TP+FP) * .cost,
      # benefit: the reverse of 30% of patient that (in fact) would cancel the appointment
      benefit = TP * .rev_rate * .benefit,
      # return of the investment
      roi = benefit-cost
    ) %>% 
    return()
}

# using threshold from 0 to 1 in 0.01 increments
simulations <- tibble(threshold = seq(0,1,.01)) %>% 
  mutate( 
    # gen the confusion matrix and roi values for this threshold
    cm  = map(threshold, genConfMatrix, .evalData=app_pred),
    roi = map(cm, calcRoi)
  ) %>% 
  unnest(roi)

# what we get
simulations %>% 
  select(-cm) %>% 
  head(10) %>% 
  knitr::kable()

# visualizing
simulations %>%           
  ggplot(aes(x=threshold, y=roi)) +
    # geom_point(size=2) +
    geom_line() +
    geom_hline(yintercept = 0, linetype="dashed", color="red") +
    geom_vline(xintercept = 0.5, linetype="dashed", color="darkgrey") +
    scale_x_continuous(breaks=seq(0,1,.1)) +
    labs(title="Return of Investment", subtitle = "Influence of the Threshold Parameter")
```

Podemos ver que o melhor _RoI_ é obtido usando um _threshold_ entre 0.2 e 0.3, e não 0.5 como normalmente definido, mais do que isso, neste nível temos uma pior _acurácia_ do modelo, veja:

```{r worstAcc}

simulations %>% 
  filter(threshold==.3) %>% 
  pull(cm) %>% 
  .[[1]] %>% 
  summary() %>% 
  select(-.estimator) %>% 
  knitr::kable()


```
 
```{r oldAcc, echo=FALSE}
newAcc <- simulations %>% 
  filter(threshold==.3) %>% 
  pull(cm) %>% 
  .[[1]] %>% 
  summary() %>% 
  filter(.metric=="accuracy") %>% 
  pull(.estimate)

oldAcc <- cm %>% 
  summary() %>% 
  filter(.metric=="accuracy") %>% 
  pull(.estimate)

```

Compare esta métrica de _acurácia_ (`r newAcc`) com o valor obtido no primeiro cálculo acima (`r oldAcc`).

### Métricas de Conclusão e Classificação

Como vimos, uma decisão de negócio não é apenas função da precisão do modelo, custos e benefícios podem afetar diferentes aspectos do modelo. Lembre-se de retornar à vida real ao aplicar o modelo em cenários e casos de negócios, para otimizar o objetivo correto.

E esteja sempre ciente das métricas de classificação.

![Classification Metrics](./images/classification_metrics.png)

```{r classMetricBehavior}
simulations %>% 
  mutate(
    metrics = map(cm, function(.x){
      .x %>% 
        summary() %>% 
        select(-.estimator) %>% 
        pivot_wider(names_from = .metric, values_from = .estimate) %>% 
        return()
    })) %>% 
  unnest(metrics) %>%
  select(threshold, accuracy, sens, spec, precision, recall) %>%
  pivot_longer(cols = -threshold, names_to = "metric", values_to = "value") %>% 
  ggplot(aes(x=threshold, y=value, color=metric))+
  geom_line() +
  labs(title="Main Classification Matrics", subtitle="Behavior in function of the logistic threshold") +
  theme_minimal()
```
